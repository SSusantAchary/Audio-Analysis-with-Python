{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Speech Recognition</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import speech_recognition as sr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sr.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#all the process happens in SpeechRecognition with the \"Recognizer\" class\r\n",
    "r = sr.Recognizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "open_speech_sample = sr.AudioFile('OSR_us_000_0011_8k.wav')\r\n",
    "with open_speech_sample as source:\r\n",
    "    osr_audio =r.record(open_speech_sample)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "type(audio)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Lets see how Speech Recognition API interpret the wav file</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "r.recognize_google(audio)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'the boy was there when the sun goes if it is used to catch him 72 source of the user is accepting the past in falakata have to be M Pata Har see it as a evening Smoky Falls Laxman he just ask question paper of the means for the surprise came across a look at the source advance'"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "#capturing segments wit offset and duration\r\n",
    "\r\n",
    "with open_speech_sample as source:\r\n",
    "    audio = r.record(source, duration=4)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "r.recognize_google(audio)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'the poem was there when the sun goes'"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "with open_speech_sample as source:\r\n",
    "    audio_1 = r.record(source, duration = 4)\r\n",
    "    audio_2 = r.record(source, duration = 4)\r\n",
    "    audio_3 = r.record(source, duration = 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "r.recognize_google(audio_1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'the poem was there when the sun goes'"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "r.recognize_google(audio_2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'what is used to catch Salmon'"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "r.recognize_google(audio_3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'is a pain in the past that you have to meet at her feet'"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "with open_speech_sample as source:\r\n",
    "    osr_audio_1 = r.record(source, offset=4, duration = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "r.recognize_google(osr_audio_1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'if water is used to catch fish'"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "#Effect of Noise on Speech Recognition\r\n",
    "jack_hammer = sr.AudioFile('audio_files_jackhammer.wav')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "with jack_hammer as source:\r\n",
    "    audio = r.record(source)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "r.recognize_google(audio)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'smell during periods'"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# try adjusting with ambient noise\r\n",
    "\r\n",
    "with jack_hammer as source:\r\n",
    "    r.adjust_for_ambient_noise(source)\r\n",
    "    audio = r.record(source)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "r.recognize_google(osr_audio_1, show_all=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'alternative': [{'transcript': 'if water is used to catch fish',\n",
       "   'confidence': 0.63066351},\n",
       "  {'transcript': 'what is used to catch fish'},\n",
       "  {'transcript': 'ivrea is used to catch fish'},\n",
       "  {'transcript': 'Shiva is used to catch fish'},\n",
       "  {'transcript': 'hi what is used to catch fish'}],\n",
       " 'final': True}"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "#Working with microphones"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install pyaudio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Lets Test with Streaming Data: The Microphone Class</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import speech_recognition as sr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "recognition_obj = sr.Recognizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mic_in = sr.Microphone()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "sr.Microphone.list_microphone_names()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone Array (Realtek(R) Au',\n",
       " 'Stereo Mix (Realtek(R) Audio)',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " 'Speakers (Realtek(R) Audio)']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "with mic_in as source:\r\n",
    "    audio = recognition_obj.listen(source)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "recognition_obj.recognize_google(audio)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hello how are you Google'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "with mic_in as source:\r\n",
    "    recognition_obj.adjust_for_ambient_noise(source)\r\n",
    "    audio = recognition_obj.listen(source)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Below is the Error happened with i choose to speak in HINDI !!! </h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "recognition_obj.recognize_google(audio)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnknownValueError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3f3014586002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecognition_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;31m# return results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_all\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"confidence\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Lets Sum up the above stuff with a quick project \"Predict the word\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import random\r\n",
    "import time \r\n",
    "\r\n",
    "import speech_recognition as sr\r\n",
    "\r\n",
    "def recognize_speech_from_mic(recognizer, microphone):\r\n",
    "\r\n",
    "    if not isinstance(recognizer, sr.Recognizer):\r\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\r\n",
    "    \r\n",
    "    if not isinstance(microphone, sr.Microphone):\r\n",
    "        raise TypeError(\" microphone must be microphone instance\")\r\n",
    "    \r\n",
    "    with microphone as source:\r\n",
    "        recognizer.adjust_for_ambient_noise(source)\r\n",
    "        audio = recognizer.listen(source)\r\n",
    "\r\n",
    "    response = {\r\n",
    "        \"success\":True,\r\n",
    "        \"error\":None,\r\n",
    "        \"transcription\":None\r\n",
    "    }\r\n",
    "\r\n",
    "    try:\r\n",
    "        response['transcription'] = recognizer.recognize_google(audio)\r\n",
    "    except sr.RequestError:\r\n",
    "        response[\"success\"] = False\r\n",
    "        response[\"error\"] = \"API unavailable\"\r\n",
    "    except sr.UnknownValueError:\r\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\r\n",
    "\r\n",
    "    return response\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\r\n",
    "    NUM_predict = 3\r\n",
    "    prompt_limit = 5\r\n",
    "\r\n",
    "    recognizer = sr.Recognizer()\r\n",
    "    microphone = sr.Microphone()\r\n",
    "\r\n",
    "    word = random.choice(WORDS)\r\n",
    "\r\n",
    "    instructions = (\r\n",
    "        \"I am thinking of one of these words : \\n\"\r\n",
    "        \"{words}\\n\"\r\n",
    "        \"You have {n} tries to guess which one. \\n\"\r\n",
    "    ).format(words = ','.join(WORDS), n=NUM_predict)\r\n",
    "\r\n",
    "    print(instructions)\r\n",
    "    time.sleep(3)\r\n",
    "\r\n",
    "    for i in range(NUM_predict):\r\n",
    "        for j in range(prompt_limit):\r\n",
    "            print('Guess {}. Speak'.format(i+1))\r\n",
    "            guess = recognize_speech_from_mic(recognizer, microphone)\r\n",
    "            if guess[\"transcription\"]:\r\n",
    "                break\r\n",
    "            if not guess[\"success\"]:\r\n",
    "                break\r\n",
    "            print(\"i didn't catch that. what did you say?\\n\")\r\n",
    "\r\n",
    "        if guess[\"error\"]:\r\n",
    "            print(\"Error:{}\".format(guess[\"error\"]))\r\n",
    "            break\r\n",
    "\r\n",
    "        print(\"You said: {}\". format(guess[\"transcription\"]))\r\n",
    "\r\n",
    "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\r\n",
    "        user_has_more_Attempts = i < NUM_predict - 1\r\n",
    "\r\n",
    "        if guess_is_correct:\r\n",
    "            print(\"Correct! you Win!\".format(word))\r\n",
    "            break\r\n",
    "        elif user_has_more_Attempts:\r\n",
    "            print(\"Incorrect, Please try again \\n\")\r\n",
    "        else:\r\n",
    "            print(\"Sorry, you lose '{}'.\".format(word))\r\n",
    "            break "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am thinking of one of these words : \n",
      "apple,banana,grape,orange,mango,lemon\n",
      "You have 3 tries to guess which one. \n",
      "\n",
      "Guess 1. Speak\n",
      "You said: mango\n",
      "Incorrect, Please try again \n",
      "\n",
      "Guess 2. Speak\n",
      "i didn't catch that. what did you say?\n",
      "\n",
      "Guess 2. Speak\n",
      "You said: Apple\n",
      "Correct! you Win!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('tf-gpu': conda)"
  },
  "interpreter": {
   "hash": "135e78ef6267b613ce7b86630936d470174b66187aad9f784a45e5cc3235687c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}